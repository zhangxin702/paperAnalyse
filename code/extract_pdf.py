import PyPDF2
import ollama
from ollama import Client as Client1

from arxiv import Client, Search, SortCriterion
from urllib.error import HTTPError
import requests
import argparse

import os 
import datetime
# è·³è½¬åˆ°æŒ‡å®šçš„æ–‡ä»¶å¤¹
from datetime import datetime

import time
   

# åˆ›å»ºæ–‡ä»¶å¤¹å’Œå­ç›®å½• æ–‡ä»¶å¤¹çš„åå­—ä¸ºå½“å¤©æ—¥æœŸ
def create_folder():
    # è·å–ç²¾ç¡®åˆ°æ¯«ç§’çš„æ—¶é—´
    now = datetime.now()
    # æ ¼å¼åŒ–ä¸º å¹´æœˆæ—¥_æ—¶åˆ†ç§’æ¯«ç§’
    time_str = now.strftime("%Y-%m-%d_%H-%M-%S-%f")[:-3]  # æˆªå–æ¯«ç§’å‰ä¸‰ä½
    folder_name = f"{time_str}"

    if not os.path.exists(folder_name):
        os.makedirs(folder_name)
    # åˆ›å»ºå­ç›®å½•
    subfolder_names = ["pdf", "sources","analyze"]


    for subfolder_name in subfolder_names:
        if not os.path.exists(folder_name + "/" + subfolder_name):
            os.makedirs(folder_name + "/" + subfolder_name)
    return folder_name

def safe_download(result):
    # å¼ºåˆ¶æ ¡éªŒPDFé“¾æ¥
    if not result.pdf_url:
        raise ValueError("æ— æ•ˆçš„PDFé“¾æ¥")
    
    # ä¸‹è½½PDF
    title = result.title
    filename = result.title + ".pdf"
    pdf_path = result.download_pdf("./pdf", filename)
    
    # æ„é€ æºç é“¾æ¥
    source_url = result.pdf_url.replace("/pdf/", "/src/")
    try:
        # å°è¯•HEADè¯·æ±‚éªŒè¯æºç å­˜åœ¨æ€§
        resp = requests.head(source_url)
        
        if resp.status_code == 200:
            result.download_source("./sources")
    except HTTPError as e:
        print(f"æºç ä¸å­˜åœ¨: {e}")
    return filename



# ä¸‹è½½pdfæ–‡ä»¶ï¼Œè¾“å…¥å…³é”®å­—å’Œä¸‹è½½æ•°é‡
def download_pdf(keyword, num):
    search = Search(
    query=keyword,  
    max_results=num,                       # é™åˆ¶è·å–10ç¯‡
    # sort_by=SortCriterion.SubmittedDate    # æŒ‰æäº¤æ—¥æœŸæ’åº
)
    # 2. åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼ˆä½¿ç”¨é»˜è®¤å‚æ•°ï¼‰
    client = Client(
    page_size=num,          # æ¯æ¬¡è¯·æ±‚è·å–50æ¡
    delay_seconds=3.5      # æ¯”å®˜æ–¹è¦æ±‚çš„3ç§’ç¨é•¿æ›´å®‰å…¨
)
    filenames = []
    for result in client.results(search):
        try:
            filenme = safe_download(result)
            filenames.append(filenme)
        except Exception as e:
            print(f"æœç´¢å¤±è´¥: {str(e)}")

   
 
            

    with open("filename.txt", "w") as f:
        for filename in filenames:
            filename = filename.split(".")[0]
            f.write(filename + "\n")
    return filenames
        


def read_pdf_text(filename):
  with open(filename, 'rb') as file:
    # åˆ›å»ºä¸€ä¸ªPDFé˜…è¯»å™¨å¯¹è±¡
    reader = PyPDF2.PdfReader(file)
    res = []
    # éå†PDFä¸­çš„æ¯ä¸€é¡µ
    for page_num in range(len(reader.pages)):
        text = reader.pages[page_num].extract_text()
        # æ·»åŠ å­—ç¬¦æ¸…ç†é€»è¾‘
        cleaned_text = text.encode('utf-8', 'ignore').decode('utf-8', 'ignore')
        res.append(cleaned_text)
    return ''.join(res)

  

def read_prompt_content():
    prompt_content = open(prompt_content, encoding='utf-8').read()
    return prompt_content


def extract_pdf(filename, prompt_content):
    pdf = read_pdf_text(filename=filename)

    response = client.chat(model='deepseek-r1:70b',
                messages = [
                           {'role': 'system', 'content': prompt_content},
                            {'role': 'user', 'content': "è¯·æå–ä»¥ä¸‹å…³é”®ä¿¡æ¯ï¼š1,æ‘˜è¦ï¼šè®ºæ–‡æ‘˜è¦çš„å…¨æ–‡ï¼Œç”¨ 2-3 å¥è¯ç®€æ´åœ°æ€»ç»“æ‘˜è¦ã€‚2,çªå‡ºé‡ç‚¹è®ºæ–‡çš„åˆ›æ–°ç‚¹å’Œè§£å†³çš„é—®é¢˜ã€‚"},
                            {'role': 'assistant', 'content': "å¥½çš„ï¼Œæˆ‘å·²ç»ç†è§£äº†ä»»åŠ¡è¦æ±‚ï¼Œè¯·æä¾›è®ºæ–‡çš„æ–‡æœ¬å†…å®¹ã€‚"},

                           
                           {'role': 'user', 'content':pdf},

 
                           
                       ],
                
                )

    


    return response['message']['content']


def extract_pdfs(filenames, prompt_content):
    
    

    for filename in filenames:
        filepath = "./pdf/"+ filename
        res = extract_pdf(filepath, prompt_content)
        with open("./analyze/"+filename + ".txt", "w") as f:
            f.write(res)
            print("è§£æå®Œæˆï¼š" + filename)
    print("è§£æå®Œæˆï¼")


    







if __name__ == "__main__":


    # è¿è¡Œè„šæœ¬æ—¶ï¼Œè¾“å‡ºæç¤ºä¿¡æ¯
    print("å¼€å§‹ä¸‹è½½arXivè®ºæ–‡...")
    begin = time.time()

        # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°è§£æ
    parser = argparse.ArgumentParser(description='arXivè®ºæ–‡ä¸‹è½½å’Œè§£æå·¥å…·')
    parser.add_argument('--keyword', type=str, default='machine learning', 
                       help='æœç´¢å…³é”®è¯ï¼Œé»˜è®¤ä¸º"machine learning"')
    parser.add_argument('--num', type=int, default=5,
                       help='ä¸‹è½½è®ºæ–‡æ•°é‡ï¼Œé»˜è®¤ä¸º5')
    # defaultè¿™é‡Œå¡«å†™è®ºæ–‡ä¸‹è½½å’ŒğŸ§æ–‡ä»¶å­˜å‚¨çš„ä½ç½®
    parser.add_argument('--path', type=str, default='',)
    args = parser.parse_args()



    client = Client1(
        host='http://192.168.99.106:11434',
        headers={'x-some-header': 'some-value'}
    )

    path = args.path
    os.chdir(path)
    foldername = create_folder()
    # è¿›å…¥åˆ°åˆ›å»ºçš„æ–‡ä»¶å¤¹ä¸­
    os.chdir(foldername)
    # ä¸‹è½½pdfæ–‡ä»¶â€¦â€¦
    filenames = download_pdf(args.keyword, args.num)
    print("æ­£åœ¨è§£æâ€¦â€¦")
    # è¯»å–prompt.txtä¸­çš„å†…å®¹
    prompt_content = open("./code/scientific_papers_prompt.txt", encoding='utf-8').read()
    # æå–pdfæ–‡ä»¶
    extract_pdfs(filenames, prompt_content)



    end = time.time()
    folderpath = os.getcwd()
    print("ä¸‹è½½å®Œæˆï¼Œæ–‡ä»¶ä¿å­˜åœ¨ï¼š" + folderpath)
    print("è€—æ—¶ï¼š" + str(end - begin) + "ç§’")



    
    
